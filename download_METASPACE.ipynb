{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cdcf2d5-71b9-4741-b0c2-9a8eeeec9c85",
   "metadata": {},
   "source": [
    "# Download of METASPACE data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d8844ff-cb8d-4ebf-9faf-79f29a92e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from metaspace import SMInstance\n",
    "from anndata import AnnData\n",
    "from metaspace2anndata import dataset_to_anndata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff541e9-4bae-4b3e-b6fe-24ec8556c0bd",
   "metadata": {},
   "source": [
    "## Date key\n",
    "\n",
    "Set the date key and directory to download the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7732feb8-6ab1-41fd-8c19-337069c8bdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import date_key, data_dir, store_dir\n",
    "import utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f649a3-f0b4-4d2c-98fa-3d7deb42839e",
   "metadata": {},
   "source": [
    "## Initialize METASPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7a4effd-c183-4fe0-9c54-0ee26c9aa6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMInstance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aa3bdf-4551-4e4b-ab04-a19eb2ee3a93",
   "metadata": {},
   "source": [
    "## Download all dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b11e5b3-420f-4947-98f4-a9833853ea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = sm.datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d58d5879-bdb5-4814-9f20-4f05d28b7263",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dss, \n",
    "            open( os.path.join(store_dir, 'all_datasets.pickle'), \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3568fc72-f1a8-4766-9454-693f96bb6c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dss = pickle.load(open(os.path.join(store_dir, 'all_datasets.pickle'), \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adced99-483d-4e7b-afc1-290f34656035",
   "metadata": {},
   "source": [
    "## Download all results tables for HMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22865b5d-fc6e-4aa5-bded-74322bd51c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all_datasets.pickle']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(store_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e9625e-5204-45f0-a93d-3f8e93b4e72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "database = ('HMDB', 'v4')\n",
    "filename = 'hmdb4_results.pickle'\n",
    "\n",
    "if filename in os.listdir(store_dir):\n",
    "    all_results_dict = pickle.load(open(os.path.join(store_dir, filename), \"rb\" ) )\n",
    "else:\n",
    "    print('Making new dict')\n",
    "    all_results_dict = {}\n",
    "\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0624ee-4742-48af-8dee-d985a0899883",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ds in dss:\n",
    "    if ds.status == 'FINISHED' and ds.id not in all_results_dict.keys():\n",
    "        if database in [(x.name, x.version) for x in ds.database_details]:\n",
    "            \n",
    "            # Download annotation table\n",
    "            tmp_tab = ds.results(database=database)\n",
    "            \n",
    "            if tmp_tab.size > 0:\n",
    "                if ds.id not in all_results_dict.keys():\n",
    "                    all_results_dict[ds.id] = tmp_tab[['ionFormula', 'ion', 'fdr', 'mz', 'offSample', 'moleculeNames', 'intensity', 'moleculeIds']]\n",
    "                    counter +=1\n",
    "            print(counter)\n",
    "\n",
    "            # Save intermediate results    \n",
    "            if (counter % 100) == 0:\n",
    "                pickle.dump(all_results_dict,\n",
    "                            # Temporary directory for saving intermediate progress if script crashes.\n",
    "                            open( os.path.join('/scratch/trose/tmp', filename + '_' + str(counter)), \"wb\" ) )\n",
    "                \n",
    "pickle.dump(all_results_dict, \n",
    "            open( os.path.join(store_dir, filename), \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3265fc0e-073b-42e9-8a85-b885c16e1889",
   "metadata": {},
   "source": [
    "## Download SwissLipids Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394fe1b9-8556-4ebb-940b-1916e27b38a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(store_dir, 'sl_coloc')\n",
    "os.mkdir(store_dir, 'sl_anndata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93095b25-4195-483d-bc9d-b11d60a4a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "database = ('SwissLipids', '2018-02-02')\n",
    "\n",
    "for ds in tqdm(dss):\n",
    "    # Filter for datasets wit SwissLipids annotation\n",
    "    if database in [(x.name, x.version) for x in ds.database_details]:\n",
    "        \n",
    "        if ds.id + '.pickle' not is os.listdir(os.path.join(store_dir, 'sl_anndata')) or ds.id + '.pickle' not is os.listdir(os.path.join(store_dir, 'sl_coloc')):\n",
    "        \n",
    "            # Download results\n",
    "            res = ds.results(fdr=0.1, database=database)\n",
    "\n",
    "            # Only consider datasets with at least 100 annotations:\n",
    "            if res.shape[0] >= 100:\n",
    "\n",
    "                # download all annotation images\n",
    "                aai = ds.all_annotation_images(fdr=0.1, \n",
    "                                               database=database, \n",
    "                                               only_first_isotope=True, \n",
    "                                               scale_intensity=False, \n",
    "                                               hotspot_clipping=False)\n",
    "\n",
    "                # Only consider images with at least 1000 pisels and 20x20 dimensions\n",
    "                if (aai[0]._images[0].size >= 1000) and (aai[0]._images[0].shape[0] >= 20) and (aai[0]._images[0].shape[1] >= 20):\n",
    "\n",
    "                    # Median filter for coloc analysis\n",
    "                    ion_array = np.array([scipy.signal.medfilt2d(x._images[0], \n",
    "                                                                 kernel_size=3).flatten() \n",
    "                                          for x in aai])\n",
    "\n",
    "                    # Save coloc in dataframe\n",
    "                    coloc_df = pd.DataFrame(pairwise_kernels(ion_array, metric='cosine'), \n",
    "                                            columns = [x.formula + x.adduct for x in aai], \n",
    "                                            index=[x.formula + x.adduct for x in aai])\n",
    "                    coloc_df.to_pickle(os.path.join(store_dir, 'sl_coloc', ds.id + '.pickle'))\n",
    "\n",
    "\n",
    "                    # Create AnData object\n",
    "                    adata = dataset_to_anndata(ds=ds,\n",
    "                                               database=database,\n",
    "                                               fdr=0.1,\n",
    "                                               results=res,\n",
    "                                               all_annotation_images=aai)\n",
    "\n",
    "                    pickle.dump(adata, open(os.path.join(store_dir, 'sl_anndata', ds.id + '.pickle'), \"wb\" ))\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (metabolomics)",
   "language": "python",
   "name": "metabolomics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
